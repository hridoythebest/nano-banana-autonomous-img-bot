from dotenv import load_dotenv
load_dotenv()

import os
import json
from google import genai
from PIL import Image
from io import BytesIO
from pathlib import Path
from datetime import datetime
import argparse
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from itertools import cycle

# Load API keys from environment variable (now a JSON array)
API_KEYS_STR = os.environ.get("GEMINI_API_KEY")
if not API_KEYS_STR:
    raise ValueError("GEMINI_API_KEY environment variable is not set. Please set it in your .env file.")

try:
    API_KEYS = json.loads(API_KEYS_STR)
    if not isinstance(API_KEYS, list):
        raise ValueError("GEMINI_API_KEY must be a JSON array of keys.")
    if not API_KEYS:
        raise ValueError("No API keys provided in GEMINI_API_KEY.")
except json.JSONDecodeError:
    raise ValueError("GEMINI_API_KEY must be valid JSON.")

# Cycle through keys
key_cycle = cycle(API_KEYS)


def is_image_file(path: Path) -> bool:
    return path.suffix.lower() in {".jpg", ".jpeg", ".png", ".webp", ".bmp"}


def discover_images(directory: Path) -> list[Path]:
    if not directory.exists() or not directory.is_dir():
        return []
    return [p for p in sorted(directory.iterdir()) if p.is_file() and is_image_file(p)]


def safe_stem(name: str) -> str:
    return "".join(c if c.isalnum() or c in ("-", "_") else "_" for c in name)


def load_prompts(prompt_file: Path) -> list[dict]:
    if not prompt_file.exists():
        raise FileNotFoundError(f"Prompt file not found: {prompt_file}")
    with prompt_file.open("r", encoding="utf-8") as f:
        data = json.load(f)
    prompts = data.get("prompts", [])
    cleaned = []
    for i, entry in enumerate(prompts):
        name = entry.get("name") or f"prompt_{i+1:02d}"
        text = entry.get("text")
        if not text:
            continue
        cleaned.append({"name": name, "text": text})
    if not cleaned:
        raise ValueError("No valid prompts found in prompt file.")
    return cleaned


def generate_from_prompt(prompt_name: str, prompt_text: str, product_img: Path, outdir: Path, model_name: str, api_key: str) -> Path | None:
    print(f"\n[Start] Prompt='{prompt_name}' with product='{product_img.name}' using key ending with {api_key[-10:]}")
    try:
        product = Image.open(product_img)
    except Exception as e:
        print(f"[Skip] Failed to open product image: {e}")
        return None

    client = genai.Client(api_key=api_key)
    max_retries = len(API_KEYS)  # Retry with all keys if needed
    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model=model_name,
                contents=[
                    prompt_text,
                    product,
                ],
            )
            break  # Success
        except Exception as e:
            error_str = str(e)
            if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                print(f"[Retry] API quota exhausted with key ending {api_key[-10:]}, switching key (attempt {attempt+1}/{max_retries})")
                # Get next key
                api_key = next(key_cycle)
                client = genai.Client(api_key=api_key)
                time.sleep(2)  # Wait before retry
                continue
            else:
                print(f"[Error] API call failed: {e}")
                return None
    else:
        print("[Error] All keys exhausted.")
        return None

    try:
        image_parts = [
            part.inline_data.data
            for part in response.candidates[0].content.parts
            if getattr(part, "inline_data", None)
        ]
    except Exception as e:
        print(f"[Error] Unexpected response structure: {e}")
        return None

    if not image_parts:
        print("[Info] No image generated by the model.")
        return None

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    outname = f"bulk_{safe_stem(prompt_name)}__{safe_stem(product_img.stem)}__{timestamp}.jpg"
    outpath = outdir / outname
    try:
        edited_image = Image.open(BytesIO(image_parts[0]))
        edited_image.save(outpath)
        print(f"[Done] Saved: {outpath}")
        time.sleep(2.5)  # Rate limit sleep
        return outpath
    except Exception as e:
        print(f"[Error] Failed to save output: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(description="Bulk generate professional ad images from prompts and product images using Gemini with multi-threading and multiple API keys.")
    parser.add_argument("--prompt_file", type=str, default=str(Path(__file__).resolve().parents[1] / "prompt.json"), help="Path to prompt JSON file.")
    parser.add_argument("--product_dir", type=str, default=str(Path(__file__).resolve().parents[1] / "product_images"), help="Directory containing product images.")
    parser.add_argument("--outdir", type=str, default=str(Path(__file__).resolve().parents[1] / "bulk_outputs"), help="Directory to save generated images.")
    parser.add_argument("--model", type=str, default="gemini-2.5-flash-image-preview", help="Model name to use.")
    parser.add_argument("--prompt_names", type=str, nargs="*", help="Optional list of prompt names to run (defaults to all).")
    parser.add_argument("--max_workers", type=int, default=20, help="Number of concurrent threads.")

    args = parser.parse_args()

    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    prompts = load_prompts(Path(args.prompt_file))
    if args.prompt_names:
        name_set = set(args.prompt_names)
        prompts = [p for p in prompts if p["name"] in name_set]
        if not prompts:
            raise ValueError("No matching prompts found for the provided --prompt_names.")

    product_dir = Path(args.product_dir)
    product_images = discover_images(product_dir)
    if not product_images:
        raise FileNotFoundError(f"No product images found in {product_dir}")

    # Create pairs with assigned keys
    pairs = []
    for p in prompts:
        for q in product_images:
            api_key = next(key_cycle)
            pairs.append((p["name"], p["text"], q, outdir, args.model, api_key))

    print(f"Total generations to run: {len(pairs)}")
    success = 0

    with ThreadPoolExecutor(max_workers=args.max_workers) as executor:
        futures = [executor.submit(generate_from_prompt, *pair) for pair in pairs]
        for future in as_completed(futures):
            if future.result():
                success += 1

    print(f"\nCompleted. Successful generations: {success}/{len(pairs)}")


if __name__ == "__main__":
    main()